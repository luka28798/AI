{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aa1cc5b",
      "metadata": {
        "id": "3aa1cc5b",
        "outputId": "67235b54-4f3b-4801-8425-dcc71cdbf2ca"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import glob\n",
        "import regex as re\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5TokenizerFast as T5Tokenizer,\n",
        "    TrainingArguments, Trainer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f1fe618",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "b917292a36e84589a80fa7eb74d70486",
            "1e469811ebf84c97a2aa684606ac575f",
            "d92d46ac2d2242b5be1fba35ded7ead8",
            "",
            "2491787b59f74a5c98775d16bea036f0"
          ]
        },
        "id": "9f1fe618",
        "outputId": "c744e774-5b75-4828-bea4-67d6c8dbd738"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-01b8410d489fd10c\n",
            "Reusing dataset csv (C:\\Users\\luka2\\.cache\\huggingface\\datasets\\csv\\default-01b8410d489fd10c\\0.0.0\\51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b917292a36e84589a80fa7eb74d70486",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-20a9484be1a2dddd\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset csv/default to C:\\Users\\luka2\\.cache\\huggingface\\datasets\\csv\\default-20a9484be1a2dddd\\0.0.0\\51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e469811ebf84c97a2aa684606ac575f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d92d46ac2d2242b5be1fba35ded7ead8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 tables [00:00, ? tables/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset csv downloaded and prepared to C:\\Users\\luka2\\.cache\\huggingface\\datasets\\csv\\default-20a9484be1a2dddd\\0.0.0\\51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2491787b59f74a5c98775d16bea036f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "load_data_train = load_dataset('csv', data_files ='./cnn_dailymail/train.csv')\n",
        "load_data_valid = load_dataset('csv', data_files ='./cnn_dailymail/validation.csv')\n",
        "\n",
        "#i = 0\n",
        "dataset_train = load_data_train['train']\n",
        "dataset_valid = load_data_valid['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3372760e",
      "metadata": {
        "id": "3372760e",
        "outputId": "588dc39d-5d3b-435c-9574-51c325be9862"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '0001d1afc246a7964130f43ae940af6bc6c57f01',\n",
              " 'article': \"By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\",\n",
              " 'highlights': 'Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\\nHe contracted the infection through contaminated food in Italy .\\nChurch members in Fargo, Grand Forks and Jamestown could have been exposed .'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f4e53fb",
      "metadata": {
        "id": "1f4e53fb"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3f8a8b2",
      "metadata": {
        "id": "d3f8a8b2",
        "colab": {
          "referenced_widgets": [
            "09e04f7695f74908bad942b18b4b7118",
            "7ec044ea826a45858f313bdebd0e9cb8"
          ]
        },
        "outputId": "396c7f26-506a-4dae-a6b9-f9c88b16d52d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-a5d7f0e1576a416d\n",
            "Reusing dataset csv (/home/jpavicic/.cache/huggingface/datasets/csv/default-a5d7f0e1576a416d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09e04f7695f74908bad942b18b4b7118",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-c845ff500875c8c8\n",
            "Reusing dataset csv (/home/jpavicic/.cache/huggingface/datasets/csv/default-c845ff500875c8c8/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ec044ea826a45858f313bdebd0e9cb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#articles = []\n",
        "#highlights = []\n",
        "load_data_train = load_dataset('csv', data_files ='./cnn_dailymail/train.csv')\n",
        "load_data_valid = load_dataset('csv', data_files ='./cnn_dailymail/validation.csv')\n",
        "\n",
        "#i = 0\n",
        "dataset_train = load_data_train['train']\n",
        "dataset_valid = load_data_valid['train']\n",
        "articles_train = dataset_train['article'][:28000]\n",
        "highlights_train = dataset_train['highlights'][:28000]\n",
        "articles_valid = dataset_valid['article'][:1500]\n",
        "highlights_valid = dataset_valid['highlights'][:1500]\n",
        "\n",
        "#i = 0\n",
        "#for article in articles_train:\n",
        "#    article = re.findall(r\"[\\w']+\", article)\n",
        "#    articles_train[i] = article\n",
        "#    i += 1\n",
        "#j = 0\n",
        "#for highlight in highlights_train:\n",
        "#    highlight = re.findall(r\"[\\w']+\", highlight)\n",
        "#    highlights_train[j] = highlight\n",
        "#    j += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "401b3759-c115-4f63-a649-02a95aeb712f",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "401b3759-c115-4f63-a649-02a95aeb712f",
        "outputId": "7514303b-456f-4104-82cd-32936dfa00c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jun 29 19:48:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
            "|  0%   40C    P8    19W / 240W |     19MiB /  7981MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      3406      G   /usr/lib/xorg/Xorg                  9MiB |\n",
            "|    0   N/A  N/A      4776      G   /usr/bin/gnome-shell                8MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13997feb",
      "metadata": {
        "id": "13997feb"
      },
      "source": [
        "DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "601c70da",
      "metadata": {
        "id": "601c70da"
      },
      "outputs": [],
      "source": [
        "class SummarizationDataset(Dataset):\n",
        "  def __init__(\n",
        "      self,\n",
        "      data_articles: list,\n",
        "      data_highlights: list,\n",
        "      tokenizer = T5Tokenizer,\n",
        "      article_max_token_len : int = 512,\n",
        "      highlight_max_token_len : int = 128\n",
        "  ):\n",
        "      self.tokenizer = tokenizer\n",
        "      self.data_articles = data_articles\n",
        "      self.data_highlights = data_highlights\n",
        "      self.article_max_token_len = article_max_token_len\n",
        "      self.highlight_max_token_len = highlight_max_token_len\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data_articles)\n",
        "\n",
        "  def __getitem__(self, index : int):\n",
        "\n",
        "    article = self.data_articles[index]\n",
        "    highlight = self.data_highlights[index]\n",
        "\n",
        "    article_encoding = tokenizer(\n",
        "        article,\n",
        "        max_length = self.article_max_token_len,\n",
        "        padding = 'max_length',\n",
        "        truncation = True,\n",
        "        return_attention_mask = True,\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = 'pt'\n",
        "    )\n",
        "    highlight_encoding = tokenizer(\n",
        "        highlight,\n",
        "        max_length = self.highlight_max_token_len,\n",
        "        padding = 'max_length',\n",
        "        truncation = True,\n",
        "        return_attention_mask = True,\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = 'pt'\n",
        "    )\n",
        "\n",
        "    labels = highlight_encoding['input_ids']\n",
        "    labels[labels == 0] = -100\n",
        "\n",
        "    return dict(\n",
        "        article = article,\n",
        "        highlight = highlight,\n",
        "        input_ids = article_encoding['input_ids'].flatten(),\n",
        "        attention_mask = article_encoding['attention_mask'].flatten(),\n",
        "        labels = labels.flatten(),\n",
        "        labels_attention_mask = highlight_encoding['attention_mask'].flatten()\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3a42caf",
      "metadata": {
        "id": "e3a42caf"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 't5-small'\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME, model_max_length = 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd18ef4c-a064-4ceb-a6e1-5211d4ed84df",
      "metadata": {
        "id": "bd18ef4c-a064-4ceb-a6e1-5211d4ed84df"
      },
      "outputs": [],
      "source": [
        "article_max_token_len = 512\n",
        "highlight_max_token_len = 128\n",
        "\n",
        "ds_train = SummarizationDataset(articles_train, highlights_train, tokenizer, article_max_token_len, highlight_max_token_len)\n",
        "ds_valid = SummarizationDataset(articles_valid, highlights_valid, tokenizer, article_max_token_len, highlight_max_token_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d2668e3-d1f4-4893-867a-7ac6a6fbbbae",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "4d2668e3-d1f4-4893-867a-7ac6a6fbbbae",
        "outputId": "a7d84200-6f42-4872-87c8-bd2083e75e1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([23705,  2037,   420,    13,  3815,   555,   227,     3, 19423,  1369,\n",
              "           44,  4712,   202,   189,   127,   855,     3,     5,  2737, 12823,\n",
              "            6, 17836,   896,     6, 20976,  1846,    11,   205, 10936,  1306,\n",
              "           66,  2328,   166,   979,    13,     8,   774,     3,     5,  7351,\n",
              "           18,    77,  6585,    52,  5199,  1008,    15,  7586,     3,     9,\n",
              "            3,   547,    18,    17,  5206,    38,  2158,   524,  5437,     3,\n",
              "          189, 12380, 16233,    15,     3, 24279,     3,     5,  4871,     7,\n",
              "           21,   933,    17,     7,  1334,    11,  7271,    32,  6372,     3,\n",
              "            5,   638,  2169,   651,    87, 18304,    26,  2590,    11,  3525,\n",
              "         1483,    87, 14714,  3833,    15,   321,   414,    16, 14924,     3,\n",
              "            5,    71,  1480,  7872,   938,  3552,   293,  1288,   177,   725,\n",
              "        18584, 14799,   386,   979,   581,  4185, 10279,     3,     5,     1,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_train[4]['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f9e7c74",
      "metadata": {
        "id": "0f9e7c74"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "dl_train = DataLoader(ds_train, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
        "dl_valid = DataLoader(ds_valid, batch_size = batch_size, shuffle = True, num_workers = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aOnK8ZW3WqeH",
      "metadata": {
        "id": "aOnK8ZW3WqeH"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "432a0cf8",
      "metadata": {
        "collapsed": true,
        "id": "432a0cf8",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "outputId": "d80be5c8-bd35-47b7-8d7d-677482034a21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict = True)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8649c54",
      "metadata": {
        "id": "c8649c54"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.AdamW(model.parameters(), lr = 0.00005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jfZBDITB4skW",
      "metadata": {
        "id": "jfZBDITB4skW"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r71BE2wBNHzV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r71BE2wBNHzV",
        "outputId": "df4ee078-4542-46f6-bb74-d7939a3231c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "395"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbf98398-fa73-4d9a-a10b-dc87815dee5a",
      "metadata": {
        "id": "dbf98398-fa73-4d9a-a10b-dc87815dee5a"
      },
      "outputs": [],
      "source": [
        "TOKENIZERS_PARALLELISM = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c054eb67-12b0-4c43-b900-7e632f49501b",
      "metadata": {
        "id": "c054eb67-12b0-4c43-b900-7e632f49501b"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load('./model_checkpoint.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa6a490f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "collapsed": true,
        "id": "aa6a490f",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "d4525e01-e611-45ad-84e7-c62f3797ef3e",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bzzz\n",
            "[1, 500] loss: 2.148\n",
            "[1, 1000] loss: 2.084\n",
            "[1, 1500] loss: 2.063\n",
            "[1, 2000] loss: 2.060\n",
            "[1, 2500] loss: 2.081\n",
            "[1, 3000] loss: 2.018\n",
            "[1, 3500] loss: 2.025\n",
            "[1, 50] validation_loss: 1.867\n",
            "[1, 100] validation_loss: 1.786\n",
            "[1, 150] validation_loss: 1.800\n",
            "Epoch 1 / 20 train_loss : 1.6262794733047485 validation_loss: 1.8668029308319092\n",
            "[2, 500] loss: 2.004\n",
            "[2, 1000] loss: 2.008\n",
            "[2, 1500] loss: 2.025\n",
            "[2, 2000] loss: 1.995\n",
            "[2, 2500] loss: 2.002\n",
            "[2, 3000] loss: 2.001\n",
            "[2, 3500] loss: 1.992\n",
            "[2, 50] validation_loss: 1.793\n",
            "[2, 100] validation_loss: 1.825\n",
            "[2, 150] validation_loss: 1.863\n",
            "Epoch 2 / 20 train_loss : 1.564241886138916 validation_loss: 1.642137885093689\n",
            "[3, 500] loss: 1.975\n",
            "[3, 1000] loss: 1.990\n",
            "[3, 1500] loss: 1.957\n",
            "[3, 2000] loss: 1.970\n",
            "[3, 2500] loss: 1.980\n",
            "[3, 3000] loss: 1.958\n",
            "[3, 3500] loss: 1.981\n",
            "[3, 50] validation_loss: 1.807\n",
            "[3, 100] validation_loss: 1.876\n",
            "[3, 150] validation_loss: 1.749\n",
            "Epoch 3 / 20 train_loss : 1.6541541814804077 validation_loss: 1.8750759363174438\n",
            "[4, 500] loss: 1.963\n",
            "[4, 1000] loss: 1.935\n",
            "[4, 1500] loss: 1.937\n",
            "[4, 2000] loss: 1.946\n",
            "[4, 2500] loss: 1.949\n",
            "[4, 3000] loss: 1.935\n",
            "[4, 3500] loss: 1.975\n",
            "[4, 50] validation_loss: 1.844\n",
            "[4, 100] validation_loss: 1.829\n",
            "[4, 150] validation_loss: 1.757\n",
            "Epoch 4 / 20 train_loss : 1.8384431600570679 validation_loss: 1.9754468202590942\n",
            "[5, 500] loss: 1.920\n",
            "[5, 1000] loss: 1.938\n",
            "[5, 1500] loss: 1.909\n",
            "[5, 2000] loss: 1.923\n",
            "[5, 2500] loss: 1.934\n",
            "[5, 3000] loss: 1.942\n",
            "[5, 3500] loss: 1.928\n",
            "[5, 50] validation_loss: 1.806\n",
            "[5, 100] validation_loss: 1.791\n",
            "[5, 150] validation_loss: 1.834\n",
            "Epoch 5 / 20 train_loss : 2.0947725772857666 validation_loss: 2.0552990436553955\n",
            "[6, 500] loss: 1.893\n",
            "[6, 1000] loss: 1.932\n",
            "[6, 1500] loss: 1.883\n",
            "[6, 2000] loss: 1.894\n",
            "[6, 2500] loss: 1.913\n",
            "[6, 3000] loss: 1.922\n",
            "[6, 3500] loss: 1.919\n",
            "[6, 50] validation_loss: 1.821\n",
            "[6, 100] validation_loss: 1.795\n",
            "[6, 150] validation_loss: 1.798\n",
            "Epoch 6 / 20 train_loss : 2.006821632385254 validation_loss: 2.181135654449463\n",
            "[7, 500] loss: 1.883\n",
            "[7, 1000] loss: 1.889\n",
            "[7, 1500] loss: 1.891\n",
            "[7, 2000] loss: 1.886\n",
            "[7, 2500] loss: 1.907\n",
            "[7, 3000] loss: 1.887\n",
            "[7, 3500] loss: 1.887\n",
            "[7, 50] validation_loss: 1.820\n",
            "[7, 100] validation_loss: 1.839\n",
            "[7, 150] validation_loss: 1.758\n",
            "Epoch 7 / 20 train_loss : 1.6461498737335205 validation_loss: 1.571216106414795\n",
            "[8, 500] loss: 1.857\n",
            "[8, 1000] loss: 1.856\n",
            "[8, 1500] loss: 1.880\n",
            "[8, 2000] loss: 1.868\n",
            "[8, 2500] loss: 1.883\n",
            "[8, 3000] loss: 1.890\n",
            "[8, 3500] loss: 1.889\n",
            "[8, 50] validation_loss: 1.818\n",
            "[8, 100] validation_loss: 1.822\n",
            "[8, 150] validation_loss: 1.825\n",
            "Epoch 8 / 20 train_loss : 2.0855982303619385 validation_loss: 1.74310302734375\n",
            "[9, 500] loss: 1.820\n",
            "[9, 1000] loss: 1.861\n",
            "[9, 1500] loss: 1.861\n",
            "[9, 2000] loss: 1.854\n",
            "[9, 2500] loss: 1.855\n",
            "[9, 3000] loss: 1.878\n",
            "[9, 3500] loss: 1.880\n",
            "[9, 50] validation_loss: 1.783\n",
            "[9, 100] validation_loss: 1.836\n",
            "[9, 150] validation_loss: 1.804\n",
            "Epoch 9 / 20 train_loss : 2.200160264968872 validation_loss: 1.9966537952423096\n",
            "[10, 500] loss: 1.828\n",
            "[10, 1000] loss: 1.829\n",
            "[10, 1500] loss: 1.853\n",
            "[10, 2000] loss: 1.853\n",
            "[10, 2500] loss: 1.835\n",
            "[10, 3000] loss: 1.844\n",
            "[10, 3500] loss: 1.852\n",
            "[10, 50] validation_loss: 1.789\n",
            "[10, 100] validation_loss: 1.855\n",
            "[10, 150] validation_loss: 1.788\n",
            "Epoch 10 / 20 train_loss : 1.6417346000671387 validation_loss: 1.8395425081253052\n",
            "[11, 500] loss: 1.821\n",
            "[11, 1000] loss: 1.829\n",
            "[11, 1500] loss: 1.822\n",
            "[11, 2000] loss: 1.834\n",
            "[11, 2500] loss: 1.841\n",
            "[11, 3000] loss: 1.837\n",
            "[11, 3500] loss: 1.814\n",
            "[11, 50] validation_loss: 1.798\n",
            "[11, 100] validation_loss: 1.853\n",
            "[11, 150] validation_loss: 1.799\n",
            "Epoch 11 / 20 train_loss : 1.6926714181900024 validation_loss: 1.4084348678588867\n",
            "[12, 500] loss: 1.810\n",
            "[12, 1000] loss: 1.797\n",
            "[12, 1500] loss: 1.798\n",
            "[12, 2000] loss: 1.814\n",
            "[12, 2500] loss: 1.825\n",
            "[12, 3000] loss: 1.819\n",
            "[12, 3500] loss: 1.838\n",
            "[12, 50] validation_loss: 1.874\n",
            "[12, 100] validation_loss: 1.842\n",
            "[12, 150] validation_loss: 1.784\n",
            "Epoch 12 / 20 train_loss : 1.8538048267364502 validation_loss: 1.963302493095398\n",
            "[13, 500] loss: 1.798\n",
            "[13, 1000] loss: 1.788\n",
            "[13, 1500] loss: 1.795\n",
            "[13, 2000] loss: 1.795\n",
            "[13, 2500] loss: 1.827\n",
            "[13, 3000] loss: 1.814\n",
            "[13, 3500] loss: 1.803\n",
            "[13, 50] validation_loss: 1.837\n",
            "[13, 100] validation_loss: 1.858\n",
            "[13, 150] validation_loss: 1.804\n",
            "Epoch 13 / 20 train_loss : 1.91143000125885 validation_loss: 1.6183574199676514\n",
            "[14, 500] loss: 1.779\n",
            "[14, 1000] loss: 1.787\n",
            "[14, 1500] loss: 1.792\n",
            "[14, 2000] loss: 1.787\n",
            "[14, 2500] loss: 1.806\n",
            "[14, 3000] loss: 1.799\n",
            "[14, 3500] loss: 1.778\n",
            "[14, 50] validation_loss: 1.827\n",
            "[14, 100] validation_loss: 1.831\n",
            "[14, 150] validation_loss: 1.846\n",
            "Epoch 14 / 20 train_loss : 1.6968967914581299 validation_loss: 1.6865748167037964\n",
            "[15, 500] loss: 1.764\n",
            "[15, 1000] loss: 1.772\n",
            "[15, 1500] loss: 1.772\n",
            "[15, 2000] loss: 1.782\n",
            "[15, 2500] loss: 1.789\n",
            "[15, 3000] loss: 1.780\n",
            "[15, 3500] loss: 1.775\n",
            "[15, 50] validation_loss: 1.814\n",
            "[15, 100] validation_loss: 1.828\n",
            "[15, 150] validation_loss: 1.849\n",
            "Epoch 15 / 20 train_loss : 1.5655388832092285 validation_loss: 1.2746448516845703\n",
            "[16, 500] loss: 1.758\n",
            "[16, 1000] loss: 1.756\n",
            "[16, 1500] loss: 1.779\n",
            "[16, 2000] loss: 1.762\n",
            "[16, 2500] loss: 1.764\n",
            "[16, 3000] loss: 1.770\n",
            "[16, 3500] loss: 1.768\n",
            "[16, 50] validation_loss: 1.814\n",
            "[16, 100] validation_loss: 1.860\n",
            "[16, 150] validation_loss: 1.791\n",
            "Epoch 16 / 20 train_loss : 1.6872059106826782 validation_loss: 2.057589292526245\n",
            "[17, 500] loss: 1.753\n",
            "[17, 1000] loss: 1.720\n",
            "[17, 1500] loss: 1.754\n",
            "[17, 2000] loss: 1.763\n",
            "[17, 2500] loss: 1.764\n",
            "[17, 3000] loss: 1.760\n",
            "[17, 3500] loss: 1.763\n",
            "[17, 50] validation_loss: 1.847\n",
            "[17, 100] validation_loss: 1.860\n",
            "[17, 150] validation_loss: 1.755\n",
            "Epoch 17 / 20 train_loss : 1.7665296792984009 validation_loss: 1.8574284315109253\n",
            "[18, 500] loss: 1.734\n",
            "[18, 1000] loss: 1.730\n",
            "[18, 1500] loss: 1.719\n",
            "[18, 2000] loss: 1.750\n",
            "[18, 2500] loss: 1.749\n",
            "[18, 3000] loss: 1.761\n",
            "[18, 3500] loss: 1.759\n",
            "[18, 50] validation_loss: 1.779\n",
            "[18, 100] validation_loss: 1.928\n",
            "[18, 150] validation_loss: 1.869\n",
            "Epoch 18 / 20 train_loss : 1.8920022249221802 validation_loss: 1.7626514434814453\n",
            "[19, 500] loss: 1.721\n",
            "[19, 1000] loss: 1.723\n",
            "[19, 1500] loss: 1.738\n",
            "[19, 2000] loss: 1.733\n",
            "[19, 2500] loss: 1.734\n",
            "[19, 3000] loss: 1.743\n",
            "[19, 3500] loss: 1.736\n",
            "[19, 50] validation_loss: 1.847\n",
            "[19, 100] validation_loss: 1.820\n",
            "[19, 150] validation_loss: 1.888\n",
            "Epoch 19 / 20 train_loss : 1.322725772857666 validation_loss: 1.564417839050293\n",
            "[20, 500] loss: 1.717\n",
            "[20, 1000] loss: 1.707\n",
            "[20, 1500] loss: 1.722\n"
          ]
        }
      ],
      "source": [
        "\n",
        "epochs = 20\n",
        "losses_train = []\n",
        "losses_valid = []\n",
        "train_losses_per_epoch = []\n",
        "valid_losses_per_epoch = []\n",
        "print(\"bzzz\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss_list': train_losses_per_epoch,\n",
        "            'validation_loss_list': valid_losses_per_epoch\n",
        "    }, './model_checkpoint.pt')\n",
        "    running_loss = 0.0\n",
        "    losses_train = []\n",
        "    losses_valid = []\n",
        "    model.train()\n",
        "    for i, data in enumerate(dl_train, 0):\n",
        "        input_ids = data['input_ids'].to(device)\n",
        "        attention_mask = data['attention_mask'].to(device)\n",
        "        labels =  data['labels'].to(device)\n",
        "        decoder_attention_mask = data['labels_attention_mask'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output_loss = model(input_ids = input_ids, attention_mask = attention_mask, decoder_attention_mask = decoder_attention_mask, labels = labels).loss\n",
        "        losses_train.append(output_loss.item())\n",
        "\n",
        "        output_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += output_loss.item()\n",
        "\n",
        "        if i % 500 == 499:\n",
        "            print(f'[{epoch + 1}, {i + 1:2d}] loss: {running_loss / 500:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    validation_running_loss = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for j, data_val in enumerate(dl_valid, 0):\n",
        "            input_ids_val = data_val['input_ids'].to(device)\n",
        "            attention_mask_val = data_val['attention_mask'].to(device)\n",
        "            decoder_attention_mask_val = data_val['labels_attention_mask'].to(device)\n",
        "            labels_val =  data_val['labels'].to(device)\n",
        "            output_loss_val = model(input_ids = input_ids_val, attention_mask = attention_mask_val, decoder_attention_mask = decoder_attention_mask_val, labels = labels_val).loss\n",
        "            losses_valid.append(output_loss_val.item())\n",
        "            validation_running_loss += output_loss_val.item()\n",
        "            if j % 50 == 49:\n",
        "                print(f'[{epoch + 1}, {j + 1:2d}] validation_loss: {validation_running_loss / 50:.3f}')\n",
        "                validation_running_loss = 0.0\n",
        "    train_losses_per_epoch.append(losses_train)\n",
        "    valid_losses_per_epoch.append(losses_valid)\n",
        "    print(f'Epoch {epoch + 1} / {epochs} train_loss : {output_loss} validation_loss: {output_loss_val}')\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Novi odjeljak"
      ],
      "metadata": {
        "id": "6dU1iioyFYO6"
      },
      "id": "6dU1iioyFYO6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Novi odjeljak"
      ],
      "metadata": {
        "id": "fl5JVKloFa7Q"
      },
      "id": "fl5JVKloFa7Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce281f8d-d9f8-41bc-8422-44f9ab382838",
      "metadata": {
        "tags": [],
        "id": "ce281f8d-d9f8-41bc-8422-44f9ab382838"
      },
      "outputs": [],
      "source": [
        "times_train = [i for i in range(0, len(losses_train))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a118144-a8fa-46ee-b7a5-b75dee120441",
      "metadata": {
        "id": "9a118144-a8fa-46ee-b7a5-b75dee120441"
      },
      "outputs": [],
      "source": [
        "len(losses_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad9e4fd-4610-4017-b325-6277c3647b79",
      "metadata": {
        "id": "aad9e4fd-4610-4017-b325-6277c3647b79"
      },
      "outputs": [],
      "source": [
        "times_valid = [i for i in range(0, len(losses_valid))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f85c4be4-1796-4c8d-9af4-b64702ea98e4",
      "metadata": {
        "id": "f85c4be4-1796-4c8d-9af4-b64702ea98e4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa51cdc0-9cc6-4c70-83ad-929670aded80",
      "metadata": {
        "id": "aa51cdc0-9cc6-4c70-83ad-929670aded80",
        "outputId": "c455ae05-440a-42b6-d6e3-5223d2f14ac8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61e25adee0>]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL0AAAEICAYAAAAKp/VCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAc8klEQVR4nO2deZgU1dX/P2dWVhlWGdYRISoQNlHAFdFEtsRE0agxLm+IGn1fTfRNRDAqJlGS+DO8BqMYF9QkbnEjCGJQRBRkFWRHlmGRfZ1hhmG2+/uja4aenl6qu6u7q6fO53n66eqqW1Vn5vnWrXPvPfceMcagKF4iI9UGKEqyUdErnkNFr3gOFb3iOVT0iudQ0SueQ0WfYkSkUEQuS7UdXkJFr3gOFb3iOVT0LkFEckVksojssj6TRSTXOtZGRGaIyBEROSQi80Ukwzp2n4h8IyLFIrJBRC5N7V/ifrJSbYBSywRgMNAPMMB7wAPAb4B7gZ1AW6vsYMCIyBnAfwPnGGN2iUgBkJlcs9MPrendw4+BR4wx+4wx+4GJwE+sYxVAPtDVGFNhjJlvfEFTVUAu0FNEso0xhcaYzSmxPo1Q0buHDsA2v9/brH0AfwI2AR+KyBYRGQdgjNkE/AJ4GNgnIq+JSAeUsKjo3cMuoKvf7y7WPowxxcaYe40x3YDvAffU+O7GmH8aYy6wzjXAH5JrdvqhoncPrwIPiEhbEWkDPAj8HUBERotIdxERoAifW1MlImeIyDCrwVsGHLeOKWFQ0buH3wFLga+AVcByax9AD2AOcAxYCPzVGPMJPn9+EnAA2AO0A8Yn1eo0RHQSieI1tKZXPIeKXvEcKnrFc0QUvYg0EpHFIrJSRNaIyMQgZYaKyFERWWF9HkyMuYoSP3bCEE4Aw4wxx0QkG/hMRGYZY74IKDffGDPa7o3btGljCgoKojBVUeyzbNmyA8aYtsGORRS9Ndx9zPqZbX3i7vIpKChg6dKl8V5GUYIiIttCHbPl04tIpoisAPYB/zHGLApSbIjlAs0SkV4hrnOriCwVkaX79++3c2tFcRxbojfGVBlj+gGdgHNFpHdAkeX4gqH6An8B3g1xnWeNMQONMQPbtg365lGUhBNV740x5gjwCTA8YH+RMeaYtT0TyLaG0hXFddjpvWkrInnWdmPgMmB9QJn2VlwIInKudd2DjlurKA5gp/cmH3hJRDLxifkNY8wMEbkdwBjzDDAG+LmIVOILerrWaHyD4lLs9N58BfQPsv8Zv+0pwBRnTVOUxKAjsorncJ3oN+8/xsLN2hxQEofrJoZf+v/mAVA4aVSKLVEaKq6r6RUl0ajoFc+holc8h4pe8RwqesVzqOgVz6GiVzyHil7xHCp6xXOo6BXPoaJXPIeKXvEcKnrFc6joFc/hftGXl8KjnWD9zFRbojQQ3C/6I9uhvJjD08ezpPBQqq1RGgDuF73FgWPlXP3MwqTc6943VvLB6j1JuZeSfNJG9MnkreU7uf3vy1JthpIg0kb0zaWUYRnLU22G0gBIG9G3l8O8kPM4HNmRalOUNMe1on905jo27CmGVW/WPVB5IjUGKQ0G162GUMOzn27h7eU7WVr5eKpNURoYrq3pAXRhQCURuFr0ipIIXC36oBW9b3FkRYkZd4te/RslAbhb9DbLVVZVU13t3QfksVnr+Gjd3lSbkTY4lVJTRORJEdkkIl+JyABHrLNZ03efMIsrn17gyC3TkanztvDTlzRpnV3s1PQ1KTX7Av2A4SIyOKDMCKCH9bkVeNoJ41aYa+rv3DoveNkdR5y4paswxvDa4u2UnKhMtSkNioiiNz4ipdS8AnjZKvsFkCci+c6aalFRlpDLupGFWw4y7u1VTPz3mlSb0qBwKqVmR8A/PmCntS/wOvGn1Kwoie28NKT0RBUAB4+Vp9iShoVTKTWD9SPWc8idSKl5orKqdvuzrw9w8JiGJSjR4UhKTXw1e2e/352AXfEYlkvw2q2swif6yqpqbnh+ET9+rn4e5wPHTvDeim/iub3SgHEkpSYwHbjR6sUZDBw1xuyOx7A7st4Le7ymh3Lz/mP1jo19aSl3v7aC/cW+t0DJiUpKy7UxqPhwKqXmTGAksAkoBW6J17AmhHBbApymiqr63Zq7jx4HoMp6Mno9NJusDGHToyPjNUtpADiVUtMAdzprWgiqfe6NsTF09eKCrXznrFMBqLQegFe+2MbpbZpyXnf3JzT37nBbYnFtaHEomi9/CkY+GPJ4aXkle4t8b4mp87Ywdd6WOsd/8+5qALq1acrH/zs0YXY6iYYbOUvaiT6jMnQ//ew1e3jhs622rrPlgHe6PpW6uFb0HeRAyGPlldW1/ro/t73SMCdza9yds7hS9L2kkFGZi0Me/9YDs5JoTepQryYxuDLK8v3c8ak2QWnAuFL0iULj8xXwnOhTbUF0pJm5aYOnRB+M8srq2tHa8spqnvjPxpBlj5ZWMHzyp2zaV1y778CxExSMe58PVtcfgHYqJFi7LJ3FdaLvLVsiF4qRYDXnVU8voOeDswHfDKQnP/o65PlzN+xj/Z5i7nljJQs2+3qXNuzxPQAvL9xWp+w7X+6k10Oza48ngqpqoy5bDLhO9JdkrEjYtV9fUn91tFXfHK3dfvHzQlvX+WrnUa7/2yJWf3M0aMAbwNz1vtDpSbPW1Ts27fOtzFkb3/S+orIKTh8/k2fmJa6SaKi4TvSJfJOPf2dVyGNT522O+nofrdsXsczcDfXnDTz877WMfTn66X1zN+yjz8OzKS2vrI2xf33J9rDnVFUbXvhsa52QbK/jOtFnSHVK7vvYrMDA0ZNhzG7hD7PWU1RWSeGBUtvnvLVsJ4/MWMtTc6N/qBsqrhO9m7j+b1/EfG6iG592ffljVmO66HhFxLJHj1cw9qUlHGjgE3NcJ/rbMmek2oRalm8/AvgE9sHq3UFDH1KNOPh0vbp4O3PW7eNvnzbsdoLrwhAaS/Lmg9oJZzhcUs7Ef6/h3RVxTQQLyvHyKv7n1S956Hs96dyqSVTnuu/xSx9cJ/pkUl4Zuf1w87QlrAyxvMjkj0L36dupf2et3s2cdXvJzcrgqR/HtlRQpLePPhz1cZ174za2BJmOWIO/W73jcCkF496v7U2x43bc88bKmGwa+eR81u/29f9vP2SvUasDXCdR0UeguMzeqOqOQ74pii8t8A1S+WvsmyPH2Wozfv+D1Xt4dXH4bkggIRPfvTLO5Wn3JhGs3V1ERVV1Hbfi/EkfA1A4aVTE82sSvF13bpc6PTTHTlTafgDjpoG/FVT0CaDwQElYtygQg6Gsoorl2w8HPb71QAl9J35Yx393c6U8e80eSssr+WH/Tqk2JSjq3iSARVsPBRXl1c8EX2T2eHkVd7/2Jdf/LXhIw+b9JfUarMFckYJx7/Pc/C0B5eoWfP6zrQx6dE7Q+9iZbG+H215Zxi9fj629kgxU9AnggXdXs2V/fR9+SWHwmnzuhv3MXuPMUtuPzqwf6wMgls/y2xlrayfOh0Ki9G8qqqp5/rOtVFTV7w3bW1RWL9p0f/EJKoOUTRYq+gRxLM6w4n8u2s7h0nBjFs47OKEaspv2HQs7AvzKwm38dsbaoJPyBz36EVf+9eQbrqisgnN+P4dHZqyN295YUdG7lPHvrOK+t0IHyEXb0zJv4z7biSv8uzdX7jjCZU/M4/kwq0zUNLBDzR/YsPdkeHVNmQ8derPFgoo+ySQ6lKHa+Hz7QDbvL2HagsKor7fNGgd4bn5o0TvVFkgWKvokc+2zCx25TiSZBVu7c8dh+9GZgewpKovcI5UmI2Aq+iQTqjEbLR+vDx/Lv253/RlbdifJhOLmF5fEdb4/e4rK2FeUmgQbKnqPMuGdVWw7WLeHqWZqo399fderX9Zu+4c8fLx+b61/bqd9MW+jbzKN/0NfMxCXbFT0HuUfi7Zzy7S6Nff0lb5I0kheypb9x/ivaUu5762v6uwPd9pNL/gW79qwp6h2X+AI8+Kth9h15HgEy+PHzvr0nUVkroiss7IL3h2kzFAROSoiK6xP6BVWFddQGWSZc4Dth8ILr8RKC1R4sIQNe4qZMneT7Xv6jwEcLClnrp+bds3UhQz90ye2rxUrdmr6SuBeY8xZwGDgThHpGaTcfGNMP+vziKNWKlFzzxsrGBMhzWhVteGVhYVUVlVzzu9PjtL+e+Uu7vvXV0HPOVRSXmeu8ZV//by2RyraduyhknJumbaEbQdLWFJ4CIDyJAxa2Vmffjew29ouFpF1+JKopW50QYnItoOlbDtYyvDe7UOW+ebIcX7z3hrKKqprs7bU8PrSHfxhTJ9650yata52BQljoKT85DziaEdyaxj6+CdJjfCMyqcXkQJ8CRqCBYkMsRIszxKRXiHOjz+7oOI4vw8RuhCMRER6Jjuk2bboRaQZ8BbwC2NMUcDh5UBXK8HyX4B3g13DieyCSnQ4LahZq/eEPBbo3nz7odnO3twh7OaRzcYn+H8YY94OPG6MKapJsGyMmQlki4j789socbFmV926L/ABK44j/ujo8YqEZUq303sjwPPAOmPMEyHKtLfKISLnWtc96KShivv585yNEZcxtNvY7TvxQwY/9lHt7+pqY3v2WSTs1PTnAz8Bhvl1SY4UkdtrMgwCY4DVIrISeBK41ugii64g2XExl0/+NOzxaJq6/u2Hp+Zu4pLHP+HrvfGvDWqn9+YzIthqjJkCTInbGsVxVn8T2Pyyz8PT1zhoCfxr2c6Yyy22ujR3Hy2jx6nN47JDR2QbOHaWOQlFLFGZ4fjfN+3Nppq16uSy559udL6XL+1EX2ayU21CWuG/KnM6cuMLi1m05aCjvVBpJ3olOr5JQixLojlUcnIGmRPRyyp6JbnEoNoyv2XGdx8pY8HmA3Elo9AlQBTXERh/8/LCbTTJyQTg11Zk520Xd+Pm8wrIb9E46utrTa+4jvlf102c/aW1erQ/U+dtYchjH8d0/bQTfXpMSFNCURrjKOvnm5wb60w70SvpzeHSyMkhEk3aiV6HedMbN8wdTzvRK+nN3hRNBvcn7UTfSFL/elRiJ7CRmgrSTvSKEi8qesVzqOgVz6GiV9KawhgmlqjolbSmtDz6rO4qeiWtiWVmmIpeSWtiCbZU0SueQ0WvpDVa0yueQ316xXNoTa94jliiblX0SloTy1xZFb3iOVT0Slqj7o3iObQhq3gQ9ekVj7Fxb4SEzkFwKrugiMiTIrJJRL4SkQFRW6IoMfDl9uiTUdtZ4awmu+ByEWkOLBOR/xhj/BOtjQB6WJ9BwNPWt6IklIT49MaY3caY5dZ2MVCTXdCfK4CXjY8vgDwRyY/eHEWJjoT33oTJLtgR2OH3eyf1HwxFcZyE9t5EyC4YbAmfeuZoSk3FDTiSXRBfzd7Z73cnYFdgIU2pqThNQqIs7WQXBKYDN1q9OIOBo1amcUVJLDG4N3Z6b2qyC64SkRXWvvFAFwBjzDPATGAksAkoBW6J3hRFSQ5OZRc0wJ1OGaUoiURHZJW0plpDixWv4Ykoyz2mZapNUFyERlkqig1U9Epa4wn3ZmN1p1SboLgIT8yRXWsKUm2C4iI8UdNrojWlDtqQVZTIpJ3oV1eflmoTFBfhiWX93q8enGoTlDQn7USvKP707xz9YKWKXklrOrZsHPU5KnrFc6jolbRGY28UxQYqesVzqOgVz6GiVzyHil5JayTs7O3gqOgVz6GiVzyHil7xHCp6xXOo6BXPoaJXPIeKXvEcKnrFc6joFc+holfSmuPlVVGfYycpwwsisk9EVoc4PlREjorICuvzYNRWKEqMbNxbHPU5dpIyTAOmAC+HKTPfGDM66rsrSgqwk1LzU+BQEmxRlKTglE8/RERWisgsEekVqpBmF1QcJ0VRlsuBrsaYvsBfgHdDFYw2u6CuRa8kgrhFb4wpMsYcs7ZnAtki0iZuy4B7K2534jKKUoe4RS8i7a20m4jIudY1D8Z73elVQ1hQHdJTUpSYidh7IyKvAkOBNiKyE3gIyIbadJpjgJ+LSCVwHLjWxLJoeACTK6/ChHkmm+RkUhpDH63SsJAYnHo7KTWvi3B8Cr4uTWdo3R0ObopYbO0jwykY975jt1XSk8bZmVGf49oR2SnX90+1CUoa8L2++VGf41rR98xvwbIHLqv9Pb7ip4w68fs6ZW45vyDJViluIzMjAe5NyjCG1s1ya3/+s+rSFBqjuJVYfHoX1vTB/4jbLu5Wb19OpgvNV1yPe2v6Gq5/Axq3YmBxK6aypc6hVk1zUmSUks64X/Tfutz3vXZvau1QGgxp4x+c2b557fbArr7whDFna05ZJXpcLPq641udWzXhzduH1NnXulkuz980MJlGKS6jYSRai3JxwmFntmPi93ux9pHLE2SQ0tBwn+ijRES46bwCmuTE1zx5+47zYhrdU9KPtBJ9yybZAPQ4tXmEkpFplF33Tx/QpWVcg12DTmsVp0VKskgr0Xdv15zXbx3MQ9/rGfe1lv/mOyGPXXJG5Fj/QLKtMYOsGEYIleTiXtGHCNQc1K01jRxwQ/zdoY/vvbjOsVjeJGMvPI2xF5zGzecVxGuaEgUd8xpESs3Ya8oJI89i2i3nRCwXOKjVrW2zOr9DRUaHq8Sb5GTxwOieNM4J/0AO79WeGwZ3iWijYg+JISuD+wenouBnF9UPVQjG4G7B/e+a/18wzb9zx3l0b9eM/5vzNc99tjUm+zY/OpLMDMEYQ5+OeYzsk0/vh2bHdC0ldhqU6BNJ/y6+AbF4ZsfURASKCNec09kBqxTfWzm62t6F7k38RAo3ranJ37vzfP44pk9c93r91sG0a55Lzw6nxHWdZPHENX1TbULKcbHoY69TF4+/lLuGdY9Yrm/nPK4ZGF2NG/g4DerWmsUTLqNZru+lecmZ7YKeN27EmVHdJ1H06ZSXahNSjvtEH0u6uABaN8ulU8smDhgTPQO6tOSKfh3q7Y+lK7Nf5zwHLFICcZ/oHSJSL0o4TmmczRX9OvDTC05z0KLIXBvg5/ft1CKp909HsmKYU9FgRT/q2/mMH3nSpWiWm8XF37I36JQh8H/X9ufsrrEtNjWgS/TnXdm/I4/+8Nt19vl3x91+8en0dUnNn2eNjKcrDbb3JiNDuPWi0+nSqinFZRVcPbAzq785yryN++nfJS/u62dlCC/cHHxM4MYhXcnKFCa8E3Sh56BcdXYnMsK4QONGnElFVTU9JsyK2lZ/nJhttuLB76b1ShTuq+l/OBXOGOlbCsQBhvduz9VWY7V3xxZ8fO/F/OxCe/354bhv+JlcFOLNISIUtG4a1fXOO7113Db586vLz6Bw0ii6tq7btunS2vm2Ts/89Oi5qsF9ou/QD657FTIT8wrt1rZZTKN40RLtcldO23TnJb5KY96vLknotMo//6gvM+++0HZ5N0z8cZ/oXYRbQ8ei7Qn6IApRBvLjQeFDJs4psB9d+tbPz6NLq9T0qvmjoo+SXCskOTszvPDi6T1ymnanNErYte12DXdq2Zizu7Z0RUWiovcjN8sn1Jysuv+W4b3a127feUl37hh6OtdFqAHP7tqSx6/uW68bMh4yLRfohsFdgx7v3q5Z0P0AT10/IOgyKsHY+LsR0RsXgRrvzUkv7oLusS2OraL349aLuvE/w7pzkxUeXBPO4P8QNMnJ4tfDz6x9QMIx5uxOcc/o8icjQ9j4uxE8ODr4fIJfXNYj5Lmj+uRz/4izbN0n8KGvoVF2RtK6Tf94VeTwkAdjnFehovejUXYm9373jFpBX3rWqfx86OlM/H7sS4bfdWl3ruzfkevOjS6cONQYQU5WRp2uza2PjazdHt2n/kiwE/xkcFcu7NGG9b8dwXt3nh/VuQ+HEOboPnXXoPSPiy+cNCpkQN7qiZez8P5hFE4axbdinEHnRHZBEZEnRWSTiHwlIgNissSFZGYI9w0/k5Zx9H7kNcnhiR/1o2mu/Rq/f5c83rxtiC1XILDXp23z3BAlIzP5R/149idn19v/2x/05pWfDorpmsPOPLXO7xp7Azu3Xv3ZYFvXa5abRX6L6CeO+ONEdsERQA/rMwh42vpWbDDnnrqztj791SW0aZ4TdqAqkN/9oDd/mr2h9nrFZRW2z23dNIfmjbIoPFjKD/p3tH3eA6POYknhyfx7U67vT0VVNb98fWXY8063Juz0CNP+SDR21qf/VEQKwhS5AnjZSsTwhYjkiUi+MWa3U0Y2ZAIbn/6DR1cN6MSLnxcGPW/xhEs5VlYJ+Bq2NY3bFo2zadE4/BjHqafksrfoBJN/1I+zu7akVdOckAkuQg03jL2wG2P9BvlG9+lgK6fr8N7tef+uC2iak8XkOV/73SfuPB62caKV1RHY4fd7p7WvnuhF5FbgVoAuXXTKXCQ6tfS9xoON1rZr3oh2MS4K8cHdF3Gw5ATd/S4QjfsViu5tm9Gvcx4rdhwJW65XhxZsO1gS9/1ixYmGbLD3cNDHNtrsgl4nr0kO/xg7iKdvqO9nx0PLpjl1BO8UGRlSL2guGjq0SNx4gj9OiH4n4N/U7gTscuC6CnB+9zYR3ZVE8qvvnhFV+bPym9vq7QoM0zAG3r/rQj785UV19jfJyeQsK7YnVKxTtDgh+unAjVYvzmDgqPrzDYdoe65qVpyroUNeIy7s0YY/X9PP1r38uyEX3j+MBeOG1c5raNPMmRgiJ7ILzgRGApuAUuAWRyxTGgRZmRkxd3fG2zUZCieyCxrgTscsUlxBXpNsjpTa7/pMJxrsJBIlPqbfeQFf7jictPslr8NSRa+EoEvrJgmZcOIGNPZGSQltYgmXcOh1oKJXUkKz3CwKJ41i2i3n0KVVEzrkhe6jdzoGX90bJaUMPaMdn/46+AJZiUJresVzqOgVz6GiV1xPtjWTKzfbGbmqT68khBduHkh5ZbUj1xrZuz2bhnVnrM38A5FQ0SsJIXDGVDxkZWZwT5SBb+FQ90bxHCp6xXOo6BXPoaJXPIeKXvEcKnrFc6joFc+holc8h4RKCZ/wG4vsB7aFONwGOJBEc6LFzfa52TZInn1djTFBl09ImejDISJLjTEDU21HKNxsn5ttA3fYp+6N4jlU9IrncKvon021ARFws31utg1cYJ8rfXpFSSRurekVJWGo6BXP4TrRi8hwEdlgpfMZl6B7dBaRuSKyTkTWiMjd1v5WIvIfEfna+m7pd879lk0bRORyv/1ni8gq69iTYuWXEZFcEXnd2r8oQmKLUHZmisiXIjLDbfZZyTf+JSLrrf/jEDfZFxZjjGs+QCawGegG5AArgZ4JuE8+MMDabg5sBHoCfwTGWfvHAX+wtntatuQCp1k2ZlrHFgND8C3PMgsYYe2/A3jG2r4WeD0GO+8B/gnMsH67xj7gJWCstZ0D5LnJvrC2p1roAf/IIcBsv9/3A/cn4b7vAd8BNgD5fg/GhmB2ALMtW/OB9X77rwOm+pextrPwjUJKFDZ1Aj4ChvmJ3hX2AacAWwPLu8W+SB+3uTehUvkkDOu12R9YBJxqrLX1re+aVYhC2dXR2g5mb+05xphK4ChQP49OaCYDvwb8Z1e7xb5uwH7gRcv9ek5EmrrIvrC4TfS2U/k4cjORZsBbwC+MMUXhigbZZ8LsD3eOHbtGA/uMMcvslA9zr4TYh6/mHQA8bYzpD5Tgc2fcYl9Y3Cb6pKXyEZFsfIL/hzHmbWv3XhHJt47nA/si2LXT2g5mb+05IpIFtAAOYY/zge+LSCHwGjBMRP7uIvt2AjuNMYus3//C9xC4xb6wuE30S4AeInKaiOTga8BMd/omVg/B88A6Y8wTfoemAzdZ2zfh8/Vr9l9r9Sichi9n7mLrFV4sIoOta94YcE7NtcYAHxvLQY2EMeZ+Y0wnY0wBvv/Bx8aYG1xk3x5gh4jUrMtxKbDWLfbZ+QNc9cGXymcjvhb+hATd4wJ8r8qvgBXWZyQ+n/Ej4Gvru5XfORMsmzZg9TBY+wcCq61jUzg5yt0IeBNfWqLFQLcYbR3KyYasa+wD+gFLrf/hu0BLN9kX7qNhCIrncJt7oygJR0WveA4VveI5VPSK51DRK55DRa94DhW94jn+P76I3SdfrnhTAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure()\n",
        "ax0 = fig.add_subplot(121, title=\"loss\")\n",
        "ax0.plot(times_train, losses_train, label='train')\n",
        "ax0.plot(times_valid, losses_valid, label='val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yK9sbC6uXqjq",
      "metadata": {
        "id": "yK9sbC6uXqjq"
      },
      "outputs": [],
      "source": [
        "new_model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5RMSMSU2PM4",
      "metadata": {
        "id": "b5RMSMSU2PM4"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load('./model_checkpoint.pt')\n",
        "new_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d6-9gyIBSxB",
      "metadata": {
        "id": "4d6-9gyIBSxB"
      },
      "outputs": [],
      "source": [
        "def summarizeText(text):\n",
        "  article_encoding = tokenizer(\n",
        "      text,\n",
        "      max_length = 512,\n",
        "      padding = 'max_length',\n",
        "      truncation = True,\n",
        "      return_attention_mask = True,\n",
        "      add_special_tokens = True,\n",
        "      return_tensors = 'pt'\n",
        "  )\n",
        "\n",
        "  generated_ids = new_model.generate(\n",
        "      input_ids = article_encoding['input_ids'],\n",
        "      attention_mask = article_encoding['attention_mask'],\n",
        "      max_length = 150,\n",
        "      num_beams = 2,\n",
        "      repetition_penalty = 2.5,\n",
        "      length_penalty = 1.0,\n",
        "      early_stopping = True\n",
        "  )\n",
        "\n",
        "  preds = [\n",
        "           tokenizer.decode(gen_id, skip_special_tokens = True, clean_up_tokenization_spaces = True)\n",
        "           for gen_id in generated_ids\n",
        "  ]\n",
        "  return \"\".join(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1oJe4vCsaB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "af1oJe4vCsaB",
        "outputId": "c2108673-ca8a-4d22-e9e2-9f91b70ffbde",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"A drunk driver who killed a young woman in a head-on crash while checking his mobile phone has been jailed for six years. Craig Eccleston-Todd, 27, was driving home from a night at a pub when he received a text message. As he was reading or replying to it, he veered across the road while driving round a bend and smashed into Rachel Titley’s car coming the other way. Craig Eccleston-Todd, 27 (left) was using his mobile phone when he crashed head-on into the car being driven by Rachel Titley, 28 (right). She died later from her injuries . The head-on crash took place in October 2013. Mr Eccleston-Todd's car was barely recognisable (pictured) Police said Eccleston-Todd had drunk at least three or four pints of beer before getting behind the wheel. He was found guilty of causing death by dangerous driving at Portsmouth Crown Court yesterday. Miss Titley, a 28-year-old solicitor’s clerk from Cowes, Isle of Wight, had also spent the evening with friends at a pub but had not drunk any alcohol, police said. She was driving responsibly and there was ‘nothing she could have done to avoid the collision’, they added. Lindsay Pennell, prosecuting, said: ‘Craig Eccleston-Todd’s driving resulted in the tragic death of a young woman, Rachel Titley, a death that could have been avoided. ‘Mr Eccleston-Todd took the decision to pick up his mobile phone whilst driving and, either reading or replying to this text message, was so distracted that he failed to negotiate a left-hand bend, crossing the central white line into the path of Miss Titley’s oncoming car. Miss Titley was pulled the wreckage of her\\xa0Daihatsu Cuore but died later from her injuries in hospital . ‘Miss Titley [had] a bright future ahead of her. She was also returning home having spent an enjoyable evening with friends and was driving responsibly. ‘She had arranged to contact her friends when she got home to confirm that she had arrived safely. Her friends sadly never heard from her after they parted company. ‘Miss Titley’s death in these circumstances reiterates the danger of using a hand-held mobile phone whilst driving.’ Police were unable to take breath or blood tests from Eccleston-Todd immediately, but in tests several hours after the accident he was only marginally under the drink-drive limit. The judge agreed with police that he would have been over the limit at the time his red Citroen hit Miss Titley’s blue Daihatsu Cuore on a road near Yarmouth, Isle of Wight, on October 11, 2013. His phone records showed he was also texting around the time of the crash. PC Mark Furse, from Hampshire constabulary’s serious collision investigation unit, said: 'Our thoughts are with Rachel's family at this time. She had been out with friends at a pub in Shalfleet that evening, but had not had any alcohol. 'Our investigation showed that there was nothing she could have done to avoid the collision and sadly it cost her her life. 'Mr Eccleston-Todd had left work in Yarmouth and met with friends at a pub where he drank at least three to four pints of lager. He hadn't long left the pub to return home when the collision occurred at around 9.30pm. 'We weren't able to take breath or blood tests from him immediately and although blood taken several hours after the collision showed he was marginally under the limit, we maintain he would have been over the limit at the time of the collision and in summing up today, the judge agreed. 'The analysis of his phone records showed that he was texting on his phone around the time of the collision so it's highly likely this would also have contributed to his dangerous driving and loss of control.' Eccleston-Todd was found guilty of causing death by dangerous driving following a trial at Portsmouth Crown Court (pictured) He added: 'Mr Eccleston-Todd will now spend six years behind bars, but Rachel's family have lost her forever. 'I hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once they're on the road. 'The dangers of drink driving and driving whilst using a mobile phone are obvious. Those who continue to do so risk spending a substantial time in prison. This case highlights just how tragic the consequences of committing these offences can be.' ‘Mr Eccleston-Todd will now spend six years behind bars, but Rachel’s family have lost her for ever. I hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once they’re on the road. This case highlights just how tragic the consequences of committing these offences can be.’ Eccleston-Todd, of Newport, Isle of Wight, was also disqualified from driving for eight years\\xa0after which he will have to complete an extended re-test.\""
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_row = articles_train[2]\n",
        "#text = 'South African authorities are investigating the deaths of at least 22 young people in a nightclub. The victims were found strewn across floors and tables the Enyobeni Tavern in the coastal town of East London. The bodies were taken to mortuaries, where post-mortem examinations - including toxicology tests - will seek to establish a cause of death. South African President Cyril Ramaphosa expressed his \"deepest condolences\" to families of the victims. \"This tragedy is made even more grave by its occurrence during Youth Month - a time during which we... advocate and advance opportunities for improved socio-economic conditions for the youth of our nation,\" he said in a tweet. Oscar Mabuyane, premier of East Cape Province where the tragedy happened, did not give possible reasons for the deaths, but condemned the \"unlimited consumption of liquor\". Speaking at the scene, he said: \"You cannot just trade in the middle of society like this and think that young people are not going to experiment.\" The incident occurred in the early hours of Sunday. Those found dead were aged between 18 and 20. A provincial safety official told AFP news agency that a stampede had been ruled out as the cause of death as there were \"no visible wounds\". \"Forensic [investigators] will take samples and test to see if there was any poisoning of any sort,\" Unathi Binqose said.'\n",
        "text = sample_row\n",
        "#text = 'Stam spices up Man Utd encounter\\n \\nAC Milan defender Jaap Stam says Manchester United \"know they made a mistake\" by selling him in 2001.\\n\\nThe sides meet at Old Trafford in the Champions League game on Wednesday and the 32-year-old\\'s Dutchman\\'s presence is sure to add spice to the fixture. \"United made a mistake in selling me,\" Stam told Uefa\\'s Champions magazine. \"I was settled at Manchester United, but they wanted to sell me. If a club want to sell you, there is nothing you can do. You can be sold like cattle.\" Sir Alex Ferguson surprised the football world - and Stam - by selling the Dutchman to Lazio for 16.5m in August 2001. The decision came shortly after Stam claimed in his autobiography that Ferguson had tapped him up when he was at PSV Eindhoven. But Ferguson insisted he sold the defender because the transfer fee was too good to refuse for a player past his prime. The affair still rankles with the Dutchman.\\n\\n\"I was settled at Manchester United, I had even just ordered a new kitchen, but they wanted to sell me,\" he said. \"In what other industry can a good employee be ushered out the door against their wishes? \"Of course, you can refuse to go, but then the club have the power to put you on the bench. I don\\'t agree that players control the game. \"There have been opportunities to confront them in the newspapers, but I have turned them down. What\\'s the point?\"\\n\\nWednesday\\'s game at Old Trafford will provide an intriguing confrontation between United\\'s young attackers Wayne Rooney and Cristiano Ronaldo and Milan\\'s veteran defence of Stam, Paolo Maldini, Cafu and Alessandro Costacurta. Stam says Rooney\\'s teenage stardom is in stark contract to his own start in the game. \"We can\\'t all be Wayne Rooneys - at his age I was training to be an electrician and thought my chance of becoming a professional footballer had gone,\" he said. \"Starting late can be a good thing. Some kids who start early get bored. \"I had my youth - having fun, drinking beers, blowing up milk cannisters. It sounds strange but it\\'s a tradition where I grew up in Kampen - and I had done all the things I wanted to do.\"\\n'\n",
        "model_summary = summarizeText(text)\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DYgqsYRKEJqy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "DYgqsYRKEJqy",
        "outputId": "08f2e13b-8b31-45df-9fa4-9702327811be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Craig Eccleston-Todd, 27, was using his mobile phone when he crashed into Rachel Titley's car. As he was reading or replying to text message he veered across road. He smashed into the 28-year-old solicitor's clerk from Cowes, Isle of Wight, coming the other way. Miss Titley died later from her injuries in hospital. Mr Eccleston-Todd was found guilty of causing death by dangerous driving.\""
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hQD1uOo4EmWj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "hQD1uOo4EmWj",
        "outputId": "20710889-0b15-4abd-97f9-19a48b9805a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Craig Eccleston-Todd, 27, had drunk at least three pints before driving car .\\nWas using phone when he veered across road in Yarmouth, Isle of Wight .\\nCrashed head-on into 28-year-old Rachel Titley's car, who died in hospital .\\nPolice say he would have been over legal drink-drive limit at time of crash .\\nHe was found guilty at Portsmouth Crown Court of causing death by dangerous driving .\""
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "highlights_train[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebbbc2c6-7fb9-48b2-b936-ba0bbf791360",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "e3ef3794aa1041ac95b19cc240eb352d"
          ]
        },
        "id": "ebbbc2c6-7fb9-48b2-b936-ba0bbf791360",
        "outputId": "51c67475-8c7d-48d6-fffc-d566a81bacee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-9f4275294e83e56b\n",
            "Reusing dataset csv (/home/jpavicic/.cache/huggingface/datasets/csv/default-9f4275294e83e56b/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3ef3794aa1041ac95b19cc240eb352d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "load_data_test = load_dataset('csv', data_files ='./cnn_dailymail/test.csv')\n",
        "dataset_test = load_data_test['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec8ad6c-d495-45e6-8424-08b2c0cdf13c",
      "metadata": {
        "id": "8ec8ad6c-d495-45e6-8424-08b2c0cdf13c"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "references = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a04e3aaf-1971-4e63-97b9-7040a0185d24",
      "metadata": {
        "id": "a04e3aaf-1971-4e63-97b9-7040a0185d24"
      },
      "outputs": [],
      "source": [
        "for i in range(0, 10):\n",
        "    predictions.append(summarizeText(dataset_test['article'][i]))\n",
        "    references.append(dataset_test['highlights'][i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f28c4ada-4419-413a-827a-3157379c0171",
      "metadata": {
        "id": "f28c4ada-4419-413a-827a-3157379c0171"
      },
      "outputs": [],
      "source": [
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fae9e5eb-2f0e-4bc9-8a9d-b8cdfa4ce51c",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "fae9e5eb-2f0e-4bc9-8a9d-b8cdfa4ce51c",
        "outputId": "50515d80-12d2-4a10-e02d-fc017acaf6ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.8/site-packages (from rouge_score) (3.6.5)\n",
            "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.8/site-packages (from rouge_score) (0.13.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /opt/anaconda3/lib/python3.8/site-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from rouge_score) (1.21.2)\n",
            "Requirement already satisfied: click in /opt/anaconda3/lib/python3.8/site-packages (from nltk->rouge_score) (8.0.3)\n",
            "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.8/site-packages (from nltk->rouge_score) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.8/site-packages (from nltk->rouge_score) (2021.8.3)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from nltk->rouge_score) (4.62.3)\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "278293ab-d144-4634-8f85-2424aab0e76a",
      "metadata": {
        "id": "278293ab-d144-4634-8f85-2424aab0e76a"
      },
      "outputs": [],
      "source": [
        "rouge = datasets.load_metric('rouge')\n",
        "results = rouge.compute(predictions=predictions, references=references)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fde3002-7d95-49e1-9324-4fd6c1f866cb",
      "metadata": {
        "id": "0fde3002-7d95-49e1-9324-4fd6c1f866cb",
        "outputId": "5cfdf597-5c36-4ccc-c48e-3b80a7c7d09f"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (2538280995.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_25717/2538280995.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    from evaluate-metric import evaluate\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "from evaluate-metric import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c014dae-2dcb-4700-b4c2-703f628a1c15",
      "metadata": {
        "id": "6c014dae-2dcb-4700-b4c2-703f628a1c15",
        "outputId": "4084b457-c59d-43dd-8d10-20946ad0adf2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'evaluate' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_25717/1439564313.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrouge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rouge'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"
          ]
        }
      ],
      "source": [
        "rouge = evaluate.load('rouge')\n",
        "results = rouge.compute(predictions=predictions, references=references)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4102d1ef-cfe5-4390-acbc-ee734fa80cf9",
      "metadata": {
        "id": "4102d1ef-cfe5-4390-acbc-ee734fa80cf9"
      },
      "outputs": [],
      "source": [
        "from rouge_score import rouge_scorer, scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d7fca3-a98d-4238-91cd-b8ae6d6c9a8a",
      "metadata": {
        "id": "20d7fca3-a98d-4238-91cd-b8ae6d6c9a8a"
      },
      "outputs": [],
      "source": [
        "rouge_types = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(rouge_types=rouge_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b6dae7f-4d74-4ee6-9336-fa5b7ca3fb58",
      "metadata": {
        "id": "0b6dae7f-4d74-4ee6-9336-fa5b7ca3fb58"
      },
      "outputs": [],
      "source": [
        "for ref, pred in zip(references, predictions):\n",
        "    score = scorer.score(ref, pred)\n",
        "\n",
        "    scores.append(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca930722-6964-45a1-b169-5506aa8588d9",
      "metadata": {
        "id": "ca930722-6964-45a1-b169-5506aa8588d9"
      },
      "outputs": [],
      "source": [
        "scores = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68613544-1b71-4618-b8fb-dc06c80efe05",
      "metadata": {
        "id": "68613544-1b71-4618-b8fb-dc06c80efe05",
        "outputId": "175668c4-ea6f-4a0b-9626-849191f82dfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'rouge1': Score(precision=0.42857142857142855, recall=0.45454545454545453, fmeasure=0.4411764705882353),\n",
              " 'rouge2': Score(precision=0.23529411764705882, recall=0.25, fmeasure=0.24242424242424243),\n",
              " 'rougeL': Score(precision=0.3142857142857143, recall=0.3333333333333333, fmeasure=0.3235294117647059),\n",
              " 'rougeLsum': Score(precision=0.34285714285714286, recall=0.36363636363636365, fmeasure=0.3529411764705882)}"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f28120c-e2f7-4114-9d73-74aefd5746d5",
      "metadata": {
        "id": "5f28120c-e2f7-4114-9d73-74aefd5746d5",
        "outputId": "1ffd68f1-666e-40cb-bbe6-ff7b4f60c407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AggregateScore(low=Score(precision=0.29887529787312844, recall=0.3776635676922718, fmeasure=0.3327264690197331), mid=Score(precision=0.40162339099698996, recall=0.45872345580037455, fmeasure=0.4175664677109717), high=Score(precision=0.5057110116479723, recall=0.5415608028008753, fmeasure=0.49610460121160604))\n",
            "AggregateScore(low=Score(precision=0.11694584670306699, recall=0.13831710861602167, fmeasure=0.12625636128392762), mid=Score(precision=0.18968356399842182, recall=0.20776775586650315, fmeasure=0.1937001888776836), high=Score(precision=0.2657493345284659, recall=0.27545491114347037, fmeasure=0.2618865553228871))\n",
            "AggregateScore(low=Score(precision=0.21245835042012934, recall=0.25871850550156233, fmeasure=0.23322135383523043), mid=Score(precision=0.29046188359309966, recall=0.3343840146038243, fmeasure=0.304211817246241), high=Score(precision=0.3806144723941489, recall=0.40057833637330903, fmeasure=0.371441522308866))\n",
            "AggregateScore(low=Score(precision=0.2575015712904361, recall=0.31904846769117845, fmeasure=0.28102686099065705), mid=Score(precision=0.3476919019852346, recall=0.3926890640766264, fmeasure=0.35764909252777277), high=Score(precision=0.4545091562765125, recall=0.4624262148883805, fmeasure=0.43842274586501834))\n"
          ]
        }
      ],
      "source": [
        "for result in results.values():\n",
        "    print(result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}