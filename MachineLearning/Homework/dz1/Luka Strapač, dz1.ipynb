{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadaća 1\n",
    "##### Rok za predaju: 03. ožujka, 2021. u 23:59h\n",
    "##### Način predaje: Teams->Strojno učenje->Assignment, predajete.ipynb datoteka (ili više datoteki u .zip) ili link na Google colab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing\n",
    "import sklearn.linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadatak 1 (5)\n",
    "___\n",
    "Pokažite kako je funkcija $J(\\theta) = \\frac{1}{2m}\\sum\\limits_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})^2$ konveksna. <br>\n",
    "(Pomoć: veza sa Hessijanom. )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaš odgovor ovdje\n",
    "___\n",
    "$J(\\theta) = \\frac{1}{2m}\\sum\\limits_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})^2$ <br>\n",
    "\n",
    "$\n",
    "\\theta = \n",
    "\\begin{bmatrix}\n",
    "\\theta_{0} \\\\\n",
    "\\theta_{1} \\\\\n",
    "\\vdots \\\\\n",
    "\\theta_{n}\n",
    "\\end{bmatrix} \n",
    "% \n",
    "\\qquad\n",
    "x^{(i)} = \n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "x_{1}^{(i)} \\\\\n",
    "\\vdots \\\\\n",
    "x_{n}^{(i)}\n",
    "\\end{bmatrix} \n",
    "$\n",
    "\n",
    "$h_{\\theta}(x^{(i)}) = x^{(i)} \\times \\theta \\qquad x = \n",
    "\\begin{bmatrix}\n",
    "\\cdots & x^{(1)^T} & \\cdots \\\\\n",
    "\\cdots & x^{(2)^T} & \\cdots \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "\\cdots & x^{(m)^T} & \\cdots \n",
    "\\end{bmatrix}_{m \\times (n+1)}\n",
    "$\n",
    "\n",
    "$J(\\theta) = \\frac{1}{2m}\\sum\\limits_{i=1}^{m}(x^{(i)}  \\theta -y^{(i)})^2 \\\\\n",
    "J(\\theta) = \\frac{1}{2m}(\\left\\| x  \\theta - y\\right\\|_{2})^2\n",
    "$\n",
    "\n",
    "Neka je $f(\\theta) = \\frac{1}{2m}\\left\\| \\theta \\right\\|_{2}^2\n",
    "f(\\theta) = \\frac{1}{2m}((\\sqrt{\\theta_{0}^2 + \\theta_{1}^2 + \\cdots + \\theta_{n}^2})^2), \\qquad \\theta_{0}^2 + \\theta_{1}^2 + \\cdots + \\theta_{n}^2 \\ge 0 \\\\\n",
    "f(\\theta) = \\frac{1}{2m}(\\theta_{0}^2 + \\theta_{1}^2 + \\cdots + \\theta_{n}^2)\n",
    "$\n",
    "\n",
    "$\\nabla ^2f =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial^2}{\\partial \\theta_0^2}f & \\frac{\\partial^2}{\\partial \\theta_0\\partial \\theta_1}f &  \\cdots  & \\frac{\\partial^2}{\\partial \\theta_0\\partial \\theta_n}f \\\\\n",
    "\\frac{\\partial^2}{\\partial \\theta_1\\partial \\theta_0}f & \\frac{\\partial^2}{\\partial \\theta_1^2}f &  \\cdots  & \\frac{\\partial^2} {\\partial\\theta_1\\partial \\theta_n}f  \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial^2}{\\partial \\theta_n\\partial \\theta_0}f & \\frac{\\partial^2} {\\partial\\theta_n\\partial \\theta_1}f & \\cdots & \\frac{\\partial^2}{\\partial \\theta_n^2}f\n",
    "\\end{bmatrix}\n",
    "\\quad = \\quad  \\frac{1}{2m}\n",
    "\\begin{bmatrix}\n",
    "2 & 0 & 0 & \\cdots & 0 \\\\\n",
    "0 & 2 & 0 & \\cdots & 0 \\\\\n",
    "0 & 0 & 2 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & 0 & \\cdots & 2 \n",
    "\\end{bmatrix} \\quad = \\quad \\frac{1}{2m} 2\\mathbb{I} \\quad = \\quad \\frac{1}{m}\\mathbb{I}\n",
    "$\n",
    "\n",
    "$\\nabla ^2f =  \\frac{1}{m}\\mathbb{I}, \\quad m \\gt 0 \\Rightarrow \\frac{1}{m} \\gt 0, \\quad \\mathbb{I}  \\gt 0\\\\$\n",
    "$\n",
    "\\nabla ^2f  \\gt 0   \\Rightarrow f$ je konveksna\n",
    "\n",
    "$x\\theta - y$ - afina funkcija $\\\\$\n",
    "$f$ - konveksna funkcija\n",
    "\n",
    "\n",
    "Teorem: Kompozicija konveksne funkcije s afinom funkcijom je konveksna. \n",
    "\n",
    "Teorem $\\Rightarrow J(\\theta) = f(x\\theta - y)$ konveksna funkcija \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadatak 2 (10)\n",
    "___\n",
    "Izračunajte gradijent funkcije $J(\\theta) = \\frac{1}{2m}\\sum\\limits_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})^2$ tj. raspišite kako biste dobili izraz dan na predavanju."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaš odgovor ovdje\n",
    "___\n",
    "$\n",
    "\\theta = \n",
    "\\begin{bmatrix}\n",
    "\\theta_{0} \\\\\n",
    "\\theta_{1} \\\\\n",
    "\\vdots \\\\\n",
    "\\theta_{n}\n",
    "\\end{bmatrix} \n",
    "% \n",
    "\\qquad\n",
    "x^{(i)} = \n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "x_{1}^{(i)} \\\\\n",
    "\\vdots \\\\\n",
    "x_{n}^{(i)}\n",
    "\\end{bmatrix} \n",
    "% \n",
    "\\qquad\n",
    "x = \n",
    "\\begin{bmatrix}\n",
    "\\cdots & x^{(1)^T} & \\cdots \\\\\n",
    "\\cdots & x^{(2)^T} & \\cdots \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "\\cdots & x^{(m)^T} & \\cdots \n",
    "\\end{bmatrix}_{m \\times (n+1)}\n",
    "% \n",
    "\\qquad\n",
    "y = \n",
    "\\begin{bmatrix}\n",
    "y^{(1)}\\\\\n",
    "y^{(2)}\\\\\n",
    "\\vdots \\\\\n",
    "y^{(m)}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$J(\\theta) = \\frac{1}{2m}\\sum\\limits_{i=1}^{m}(x  \\theta -y)^2 = \\frac{1}{2m}(x  \\theta -y)^T(x  \\theta -y) = \\frac{1}{2m}((x\\theta)^T -y^T)(x  \\theta -y)$\n",
    "\n",
    "Prisjetimo se : $x^T\\theta^Ty = (y^T\\theta x)^T$\n",
    "\n",
    "$J(\\theta) = \\frac{1}{2m}(\\theta^Tx^Tx\\theta - \\theta^Tx^Ty - y^Tx\\theta + y^Ty) =  \\frac{1}{2m}(\\theta^Tx^Tx\\theta - 2\\theta^Tx^Ty + y^Ty)$\n",
    "\n",
    "$\\frac{\\partial}{\\partial \\theta}J(\\theta) = \\frac{1}{2m}\\frac{\\partial}{\\partial \\theta}(\\theta^Tx^Tx\\theta - 2\\theta^Tx^Ty + y^Ty)\n",
    "= \\frac{1}{2m}(x^Tx\\theta + \\theta^Tx^Tx -2x^Ty) = \\frac{1}{2m}(2x^Tx\\theta -2x^Ty) = \\frac{1}{m}(x^Tx\\theta -x^Ty)$\n",
    "\n",
    "$\\frac{\\partial}{\\partial \\theta}J(\\theta) = 0 \\Leftrightarrow x^Tx\\theta -x^Ty = 0$\n",
    "\n",
    "$(x^Tx)^{-1}/ \\quad x^Tx\\theta = x^Ty \\\\\n",
    "\\theta = (x^Tx)^{-1}x^Ty$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Zadatak 3 (15)\n",
    "___\n",
    "Neka su zadani ulazni podaci $X\\in \\mathbb{R}^{m\\times n}$ i pripadne izlazne vrijednosti $y\\in\\mathbb{R}^{m}$. Na ovim podacima možemo provesti proces učenja modela linearne regresije. <br>\n",
    "Znamo kako se učenje svodi na minimizaciju funkcije $J(\\theta) = \\frac{1}{2m}\\sum\\limits_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})^2$ te kako do rješenje tog minimizacijskog problema možemo doći gradijentnom metodom. <br>\n",
    "Implementirajte gradijentnu metodu za učenje modela linearne regresije u općenitom slučaju kada su ulazni podaci dimenzije $X\\in \\mathbb{R}^{m\\times n}$.<br>\n",
    "\n",
    "Dodajte sljedeću mogućnost svojoj implementaciji gradijentne metode: crtanje grafa ovisnosti funkcije troška $J(\\theta)$ o iteracijama. (U svakoj iteraciji spremite vrijednost funkcije troška)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kod ovdje\n",
    "\n",
    "def gradientMethod(X, Y, costs):\n",
    "    b0 = 0\n",
    "    b1 = 1\n",
    "    st = 0.001\n",
    "\n",
    "    for k in range(1000):\n",
    "        cost = 0\n",
    "        cost1 = 0\n",
    "        cost2 = 0\n",
    "        for i in range(len(X)):\n",
    "            oldy = (b0 + b1*X[i])\n",
    "            cost = cost + (Y[i] - oldy)**2\n",
    "\n",
    "            for j in range(len(X)):\n",
    "                pb0 = -2*(Y[j]-(b0+b1*X[j]))\n",
    "                pb1 = (-2*X[j])*(Y[j]-(b0+b1*X[j]))\n",
    "                cost1 = cost1 + pb0\n",
    "                cost2 = cost2 + pb1\n",
    "            b0 = b0 - st*cost1\n",
    "            b1 = b1 - st*cost2\n",
    "        costs.append(cost)\n",
    "    return b0,b1\n",
    "\n",
    "costs = []\n",
    "X = np.array([2,4,5], dtype = 'int64')\n",
    "y = np.array([1.2,2.8,5.3], dtype = 'int64')\n",
    "gradientMethod(X,y, costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(np.arange(1, len(costs)+1),costs, linewidth = 10)\n",
    "plt.title(\"Ovisnost funkcije troška o iteracijama\")\n",
    "plt.xlabel(\"Iteracije\")\n",
    "plt.ylabel(\"Trošak\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadatak 4 (15)\n",
    "___\n",
    "U datoteci house_train.csv i house_test.csv su vam dani podaci o nekretninama, koji sadrže različite karakteristike nekretnina poput površine ili broja soba te cijenu. Cilj narednih zadataka će biti uspostaviti linearnu regresiju između različitih karakteristika kuće u svrhu predviđanja cijene nekretnine. \n",
    "\n",
    "Kao ulaznu varijablu uzmite sqft_living, a kao izlaznu varijablu price. \n",
    "\n",
    "1. Učitajte podatke koji su vam dani u datoteci *house_train.csv*. Skalirajte podatke koristeći metodu objašnjenu na sljedećem [linku](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale) \n",
    "\n",
    "1. Koristeći proizvoljnu biblioteku vizualizirajte odnos varijable ulaznih i izlaznih podataka. \n",
    "\n",
    "1. Koristeći *numpy array* napravite matricu dizajna $X\\in \\mathbb{R}^{m\\times (n+1)}$ i vektor izlaznih podataka $y \\in \\mathbb{R}^{m}$. \n",
    "\n",
    "1. Pokrenite gradijentnu metodu koju ste implementirali u prethodnom zadatku i pomoću nje odredite parametre $\\theta_0$ i $\\theta_1$. (Stopu učenja i broj iteracija odredite sami)\n",
    "\n",
    "1. Pravac određen izračunatime  parametrima $\\theta_0 + \\theta_1 x$ prikažite na grafu iz podzadatka b).\n",
    "1. Nacrtajte  graf promjene funkcije troška $J(\\theta)$ kroz iteracije.\n",
    "1. Učitajte podatke iz datoteke \\textit{house\\_test.csv}, spremite ih u odgovarajuće \\textit{numpy arrays} $X_{test}$ i $y_{test}$. Pazite, $X_{test}$ je ponovno matrica dizajna kao i $X$. Kao u podzadatku b), podatke prikažite  grafički.\n",
    "1. Na učitanim podacima za testiranje provedite testiranje vašeg modela tako da izračunate pogrešku kao što smo pokazali na vježbama. Ispišite vrijednost pogreške.\n",
    "\n",
    "8. Za podatke $X$ i $y$ učitane iz datoteke *house\\_train.csv* odredite opet parametre $\\theta_0, \\theta_1$, ali koristeći gotovu implementaciju iz [*sklearn*](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html}{sklearn.LinearRegression) biblioteke. (Pazite na dimenzije)\n",
    "\n",
    "1. Na učitanim podacima za testiranje provedite testiranje ovog modela kao što smo pokazali na vježbama. Ispišite vrijednost pogreške.\n",
    "\n",
    "1. Razlikuju li se model kojeg ste dobili koristeći vašu implementaciju gradijentne metode i model kojeg ste dobili koristeći gotovu implementaciju iz *scikit-learn* paketa? \n",
    "\n",
    "1. Za podatke $X$ i $Y$ učitane iz datoteke *house_train.csv* odredite opet parametre $\\theta_0, \\theta_1$, ali koristeći sustav normalnih jednadžbi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kod ovdje\n",
    "\n",
    "#a)\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('./Podaci/house_train.csv', usecols=['sqft_living', 'price'])\n",
    "dataset = scale(dataset)\n",
    "\n",
    "\n",
    "#c)\n",
    "X = np.array(dataset[:, :-1])\n",
    "y = np.array(dataset[:, 1])\n",
    "\n",
    "#b)\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.show()\n",
    "\n",
    "#d)\n",
    "costs = []\n",
    "print(gradient(X,y, costs))\n",
    "\n",
    "#e)\n",
    "T = gradient(X, y, costs)\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, T[0] + T[1]*X, color='red')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#f)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(np.arange(1, len(costs)+1),costs, linewidth = 10)\n",
    "plt.title(\"Ovisnost funkcije troška o iteracijama\")\n",
    "plt.xlabel(\"Iteracije\")\n",
    "plt.ylabel(\"Trošak\")\n",
    "\n",
    "#g)\n",
    "testset = pd.read_csv('./Podaci/house_test.csv', usecols=['sqft_living', 'price'])\n",
    "testset = scale(testset)\n",
    "X_test = np.array(testset[:, :-1])\n",
    "y_test = np.array(testset[:, 1])\n",
    "plt.scatter(X_test, y_test)\n",
    "plt.plot(X_test, T[0] + T[1]*X_test, color='red')\n",
    "plt.show()\n",
    "\n",
    "#h)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X,y)\n",
    "\n",
    "pogreska = 0\n",
    "predikcija = lr.predict(X)\n",
    "for i, prediction in enumerate(predikcija):\n",
    "    pogreska += (prediction - y[i])**2\n",
    "\n",
    "m, n = X.shape\n",
    "print(pogreska/(2*m))\n",
    "\n",
    "#i)\n",
    "theta_train_s = sklearn.linear_model.LinearRegression().fit(X_train,Y_train)\n",
    "print(\"Theta vrijednosti izračunate s sklearn.LinearRegresion: \", theta_train_s.coef_)\n",
    "\n",
    "#j)\n",
    "p = 0\n",
    "\n",
    "pred = theta_train_s.predict(X_train)\n",
    "\n",
    "for i, pr in enumerate(pred):\n",
    "    p += (pr - Y_train[i])**2\n",
    "\n",
    "gg, ggg = X_train.shape\n",
    "print(p/(2*gg))\n",
    "\n",
    "#k) koristeci scikit learn [0.         0.69976444]\n",
    "    # koristeci svoju implementaciju  [0.0006962], [0.69997346] => razlikuju se na 4. decimalu\n",
    "\n",
    "#l)\n",
    "def snj(X,Y):\n",
    "    a = np.linalg.inv(np.dot(np.transpose(X),X))\n",
    "    b = np.dot(np.transpose(X),Y)\n",
    "    return np.transpose(np.dot(a,b))\n",
    "\n",
    "theta_train_n = snj(X_train,Y_train);\n",
    "print(theta_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadatak 5 (15)\n",
    "___\n",
    "U ovom zadatku ulazni podaci će biti višestruki. Izlazna varijabla je i dalje price. \n",
    "1. Odaberite nekoliko karakteristika koje će vam biti ulazni podaci. Reprezentirajte ih kao \\textit{numpy arrays}.  (Npr. 3 karakteristike)\n",
    "1. Izračunajte parametre $\\theta_0, \\theta_1$ koristeći implementaciju gradijentne metode iz trećeg zadatka. \n",
    "1. Učitajte podatke iz datoteke \\textit{house\\_test.csv}, spremite ih u odgovarajuće \\textit{numpy arrays} $X_{test}$ i $y_{test}$.\n",
    "1. Na učitanim podacima za testiranje provedite testiranje vašeg modela tako da izračunate pogrešku kao što smo pokazali na vježbama. Ispišite vrijednost pogreške."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kod ovdje\n",
    "#a)\n",
    "dataset = pd.read_csv('./Podaci/house_train.csv', usecols=['sqft_living', 'floors', 'sqft_basement', 'price'])\n",
    "dataset = scale(dataset)\n",
    "X = np.array(dataset[:, :-1])\n",
    "y = np.array(dataset[:, 3])\n",
    "\n",
    "#b)\n",
    "#costs = []\n",
    "#print(gradientMethod(X,y, costs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
